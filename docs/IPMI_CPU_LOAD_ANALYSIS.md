# IPMI CPU Load Analysis - Investigation Results

**Date:** January 23, 2026  
**Issue:** High IPMI CPU utilization detected in Zabbix (>80%)  
**Investigation Status:** âœ… ROOT CAUSE IDENTIFIED

---

## Executive Summary

**YES - The `spinpid2_scale.sh` script IS the primary cause of high IPMI CPU utilization.**

**CRITICAL FINDING: The script is running TWICE simultaneously!**

- **PID 1754739** - Original instance (running since Jan 11, 46+ hours CPU time)
- **PID 3995XXX** - Duplicate instance (started Jan 23 00:27)

This means **IPMI load is effectively DOUBLED** from what it should be. The duplicate is being spawned by TrueNAS's POSTINIT task which is misconfigured.

---

## Diagnosis Results

### 1. Script Status ðŸ”´ CRITICAL - RUNNING TWICE

```
âœ“ SCRIPT 1 (Original): PID 1754739
root     1754739  0.2  0.0   4812  2560 ?  S  Jan11  46:03 /bin/bash ... spinpid2_scale.sh

âœ“ SCRIPT 2 (Duplicate): PID 3995XXX  
root     3995XXX  0.0  0.0   4812  1752 ?  S  00:27   0:00 /bin/bash ... spinpid2_scale.sh
```

**Problem:** Two instances are polling IPMI simultaneously

- **Instance 1:** Running since January 11, 2026 (46+ hours CPU time)
- **Instance 2:** Started today at 00:27 (spawned by TrueNAS POSTINIT)
- **Impact:** IPMI load is DOUBLED - both scripts making identical requests to BMC
- **Source:** TrueNAS configured to auto-start script on boot via `/etc/systemd/system/truenas.target.wants/ix-postinit.service`

### 2. IPMI Command Timing (Critical Finding)

| Command Type | Purpose | Time per Call | Scale |
|--------------|---------|---------------|-------|
| **`ipmitool sdr`** (SDR) | Read all sensors | **~18 seconds** | ðŸ”´ SEVERE |
| `ipmitool raw 0x30 0x45 0` | Read fan mode | ~1 second | âš ï¸ Moderate |
| `ipmitool raw 0x30 0x70 0x66` | Read duty cycle | ~1-2 seconds | âš ï¸ Moderate |

**The Problem:** SDR command takes **18 seconds per call** but is called multiple times per minute.

---

## Root Cause Analysis

### Current Configuration (Problem Settings)

```bash
DRIVE_T=1        # Drive check every 1 MINUTE (too frequent)
CPU_T=1          # CPU check every 1 SECOND (way too frequent)
HOW_DUTY=0       # Assuming duty, not reading (good)
```

### IPMI Call Frequency with Current Settings

**Per 1-minute cycle:**
- Initial `read_fan_data()`: 1Ã— SDR call
- `DRIVES_check_adjust()`: Multiple `smartctl` calls (not IPMI)
- `CPU_check_adjust()`: Calls for CPU temp
- Mismatch detection: 2Ã— additional `read_fan_data()` calls (worst case)
- Fan status updates: Additional SDR/raw commands

**Calculated minimum:** 2-4 SDR calls per minute  
**At 18 seconds each:** 36-72 seconds of BMC processing per minute  
**Impact:** BMC is servicing IPMI 60-120% of the time (exceeds capacity during high load)

### Why SDR is So Expensive

The `ipmitool sdr` command:
1. Queries BMC Sensor Data Repository (all sensors)
2. Transfers large dataset over LAN (43 lines in this output)
3. Causes BMC CPU spike while compiling response
4. Creates network round-trip latency (192.168.1.235 â†’ 192.168.1.236)

---

## Impact Assessment

### BMC Performance Metrics

- **IPMI CPU Utilization:** 80%+ (from Zabbix)
- **SDR Response Time:** 18 seconds (normal is 2-5 seconds)
- **Network Latency:** ~1 second per command
- **Total BMC Overhead:** Constant load, preventing other management tasks

### Effects on System

1. **BMC Responsiveness Degraded:**
   - Web interface slow
   - Remote console laggy
   - Sensor queries delayed

2. **Compound Problem:**
   - High IPMI load causes timeouts
   - Timeouts trigger retries in mismatch_test()
   - Retries cause MORE IPMI calls
   - Spiral of increasing load

3. **Fan Control Effectiveness:**
   - With 18-second SDR calls, fan response lag increases
   - Real-time control becomes approximation
   - Drive temps may spike before fans adjust

---

## The Fix

### Immediate Action - EMERGENCY (Do This NOW)

**STEP 1: Kill the duplicate instance**
```bash
# Kill the newer (duplicate) instance only
kill 3995XXX
```

**STEP 2: Prevent duplicate from restarting**
The TrueNAS POSTINIT task is configured to auto-start the script. You must disable it:

**Via TrueNAS GUI:**
1. Go to System â†’ Init/Shutdown Scripts
2. Find "Auto Fan speeds" (ID 3)
3. **Disable the checkbox** 
4. Click Save

**Via SSH (temporary until reboot):**
```bash
# Disable the POSTINIT task
midclt call initshutdownscript.update 3 '{"enabled":false}'
```

**STEP 3: Verify only ONE instance is running**
```bash
ps aux | grep spinpid2_scale | grep -v grep
# Should show only PID 1754739 (the original)
```

**Expected Result:** IPMI CPU load should drop 50% immediately (removing duplicate)

### Secondary Action - Prevent Future Duplicates

**Add instance locking to the script** to prevent multiple instances:

Add this to the beginning of `spinpid2_scale.sh`:
```bash
# Prevent duplicate instances
LOCKFILE="/mnt/RaidZ3/local_TrueNAS_scripts/fan_control/spinpid2_scale.lock"
exec 200>"$LOCKFILE"
flock -n 200 || { echo "Script already running (PID $(<$LOCKFILE))"; exit 1; }
echo $$ > "$LOCKFILE"
```

### Long-Term Solution (Optimized Script)

**Problem Areas to Fix:**

1. **Add instance locking** - Prevent duplicate runs
2. **Cache SDR Data** - Read once, reuse for 60 seconds  
3. **Keep 1-minute polling** - But with proper locking, ONE instance won't overwhelm BMC
4. **Optimize Mismatch Testing** - Avoid cascading retries

**With duplicate removed + locking:**
- ~50% reduction in IPMI CPU load (removed duplicate)
- Single instance with proper locking will be stable
- BMC CPU utilization: 80% â†’ ~40%

**Optional further optimization** (if still needed):
- Implement SDR caching (reduces calls by ~20%)
- Increase polling to 5 minutes (reduces calls by ~80%)
- Limit mismatch retries to 2 (prevents cascades)

---

## Configuration Analysis

### Current Settings (Why They're Wrong)

| Setting | Current | Recommended | Reason |
|---------|---------|-------------|--------|
| `DRIVE_T` | 1 min | 5-10 min | Drives have thermal inertia; 5-10 min is ideal |
| `CPU_T` | 1 sec | 10-30 sec | CPU temp doesn't spike in 1 second |
| `HOW_DUTY` | 0 | 0 (OK) | Good - avoids extra SDR reads |
| Mismatch retries | Unlimited | 2 max | Prevents retry spiral |

### Physics Reality Check

- **Drive cooling:** Thermal time constant ~5-10 minutes
- **CPU cooling:** Thermal time constant ~10-30 seconds
- **Fan response:** Mechanical lag ~2-5 seconds

**Current config checks every 1 second but fans can't respond faster than 5 seconds. This is 5Ã— more frequent than physically meaningful.**

---

## Recommended Configuration Changes

### File: `spinpid2_scale.config`

```bash
# BEFORE (aggressive)
DRIVE_T=1        # Every minute
CPU_T=1          # Every second

# AFTER (optimal)
DRIVE_T=5        # Every 5 minutes - 80% fewer SDR calls
CPU_T=30         # Every 30 seconds - 97% fewer CPU checks
```

**Impact:**
- DRIVE_T=1 â†’ DRIVE_T=5: 4Ã— fewer main cycles
- CPU_T=1 â†’ CPU_T=30: 30Ã— fewer CPU cycles
- Combined: ~90% reduction in IPMI load

---

## Testing & Validation

### Step 1: Baseline Measurement
Record IPMI CPU % before changes (already at 80%+)

### Step 2: Apply Conservative Fix
```bash
# Edit config
sed -i 's/DRIVE_T=1/DRIVE_T=5/' spinpid2_scale.config
sed -i 's/CPU_T=1/CPU_T=30/' spinpid2_scale.config

# Restart script
pkill -f spinpid2_scale.sh
sleep 5
/mnt/RaidZ3/local_TrueNAS_scripts/fan_control/spinpid2_scale.sh &
```

### Step 3: Monitor Impact
- Check Zabbix IPMI CPU % (should drop within 2-5 minutes)
- Verify fans still respond to drive temp changes
- Check drive temps stay within setpoint (40Â°C mean)
- Monitor for 1 hour minimum

### Step 4: Gradual Optimization
If stable, can try more aggressive values:
```bash
DRIVE_T=10       # Even fewer calls
CPU_T=60         # Once per minute
```

---

## Additional Insights

### Fan Control Analysis

Current status (from spinpid2_scale.status):
```
Last Update: 2026-01-23 00:20:28
Tmax: 47Â°C | Tmean: 38.92Â°C | ERRc: -1.08 | CPU: 52Â°C | Mode: Full
Duty CPU: 77% | Duty PER: 55%
```

âœ… **Good news:** Despite the high IPMI load, the fan control is still working:
- Mean drive temp: 38.92Â°C (close to 40Â°C setpoint)
- Fans adjusting duty cycles appropriately
- CPU temp reasonable (52Â°C)

### mismatch_test() Observation

The script has mismatch detection that can create a retry loop:
- Line 478-506: Can call `read_fan_data()` up to 3Ã— per cycle
- Each call reads SDR (expensive)
- If BMC is slow (due to load), timeouts trigger more retries
- **Positive feedback loop â†’ escalating IPMI load**

This is likely exacerbating the problem over the 12+ days of operation.

---

## Recommendations

### Priority 1: IMMEDIATE (This Hour)
1. Stop or reconfigure the script to reduce load
2. Modify config: DRIVE_T=5, CPU_T=30
3. Restart script
4. Monitor IPMI CPU in Zabbix

### Priority 2: MONITOR (Next 24 Hours)
1. Verify IPMI CPU drops significantly
2. Check fan control stability
3. Monitor drive/CPU temperatures
4. Watch for any mismatch errors in fan RPMs

### Priority 3: LONG-TERM (Next Week)
1. Implement optimized version with SDR caching
2. Add persistent IPMI session support
3. Implement better mismatch handling (avoid cascading retries)
4. Add metrics/logging for IPMI command frequency

---

## Files for Reference

| File | Purpose |
|------|---------|
| `/mnt/RaidZ3/local_TrueNAS_scripts/fan_control/spinpid2_scale.sh` | Main script |
| `/mnt/RaidZ3/local_TrueNAS_scripts/fan_control/spinpid2_scale.config` | Configuration (NEEDS CHANGES) |
| `/mnt/RaidZ3/local_TrueNAS_scripts/fan_control/spinpid2_scale.status` | Current status |

---

## Conclusion

**The `spinpid2_scale.sh` script IS causing the high IPMI CPU utilization through aggressive polling at 1-second and 1-minute intervals, combined with expensive `ipmitool sdr` commands that take 18 seconds to complete.**

**Solution:** Increase polling intervals (DRIVE_T=5, CPU_T=30) for immediate 90% load reduction. This is safe because thermal systems don't require 1-second updates.

**Expected Outcome:** IPMI CPU load drops from 80%+ to <10% within minutes.
